<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="CVPR 2025: EoMT shows ViTs can segment efficiently and effectively without adapters or decoders." />
  <meta name="keywords" content="EoMT, ViT, vision transformer, transformers, image segmentation, semantic segmentation, instance segmentation, panoptic segmentation, segmentation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Your ViT is Secretly an Image Segmentation Model (CVPR 2025)</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-5TCTFJM8NG"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-5TCTFJM8NG');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" type="image/png" href="./static/images/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="./static/images/favicon.svg" />
  <link rel="shortcut icon" href="./static/images/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="./static/images/apple-touch-icon.png" />
  <meta name="apple-mobile-web-app-title" content="EoMT" />
  <link rel="manifest" href="./static/images/site.webmanifest" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://www.tue-mps.org">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Your ViT is Secretly an Image Segmentation Model (CVPR 2025)</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://tommiekerssies.com/" target="_blank">Tommie Kerssies</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=Pr4XHRAAAAAJ" target="_blank">Niccolò Cavagnero</a><sup>2,*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.de/citations?user=V0iMeYsAAAAJ" target="_blank">Alexander Hermans</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=q7sm490AAAAJ" target="_blank">Narges Norouzi</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://www.giuseppeaverta.me" target="_blank">Giuseppe Averta</a><sup>2</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=ZcULDB0AAAAJ" target="_blank">Bastian Leibe</a><sup>3</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.nl/citations?user=wy57br8AAAAJ" target="_blank">Gijs Dubbelman</a><sup>1</sup>,</span>
            <span class="author-block"><a href="https://ddegeus.github.io/" target="_blank">Daan de Geus</a><sup>1,3</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Eindhoven University of Technology,</span>
            <span class="author-block"><sup>2</sup>Polytechnic of Turin,</span>
            <span class="author-block"><sup>3</sup>RWTH Aachen University</span>
          </div>
          <p class="has-text-centered mt-1" style="font-size: 0.6em;"> <em>* Work done while visiting RWTH.</em></p>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2503.19108"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tue-mps/eomt"
                   class="external-link button is-normal is-rounded is-dark"
                   target="_blank">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-vcentered">
        <div class="column">
          <figure class="image">
            <img src="./static/images/teaser_arch.svg" alt="Architecture Diagram">
          </figure>
        </div>
        <div class="column">
          <figure class="image">
            <img src="./static/images/teaser_plot.svg" alt="Performance Plot">
          </figure>
        </div>
      </div>
      <p class="has-text-centered" style="font-size: 0.6em;">
        [1] Bowen Cheng et al., <em>Masked-attention Mask Transformer for Universal Image Segmentation</em>, CVPR 2022.&nbsp;&nbsp;
        [2] Zhe Chen et al., <em>Vision Transformer Adapter for Dense Predictions</em>, ICLR 2023.
      </p>
    </div>
  </div>
</section>

<section class="hero is-light">
  <div class="hero-body container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision Transformers (ViTs) have shown remarkable performance and scalability across various computer vision tasks. To apply single-scale ViTs to image segmentation, existing methods adopt a convolutional adapter to generate multi-scale features, a pixel decoder to fuse these features, and a Transformer decoder to make predictions.
          </p>
          <p>
            In this paper, we show that the inductive biases introduced by these task-specific components can instead be learned by the ViT itself, given sufficiently large models and extensive pre-training. Based on these findings, we introduce the <em>Encoder-only Mask Transformer</em> (EoMT), which repurposes the plain ViT architecture for efficient image segmentation.
          </p>
          <p>
            With large-scale models and pre-training, EoMT achieves segmentation accuracy similar to state-of-the-art methods while being significantly faster due to its architectural simplicity.
          </p>
        </div>
      </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Encoder-only Mask Transformer (EoMT)</h2>
        <img src="./static/images/arch.svg" alt="Method figure" style="width:70%; margin-top:1em;" />
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{kerssies2025eomt,
  author     = {Kerssies, Tommie and Cavagnero, Niccolò and Hermans, Alexander and Norouzi, Narges and Averta, Giuseppe and Leibe, Bastian and Dubbelman, Gijs and de Geus, Daan},
  title      = {Your ViT is Secretly an Image Segmentation Model},
  booktitle  = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year       = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/tue-mps" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
